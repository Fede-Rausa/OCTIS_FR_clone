{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98eedc81",
   "metadata": {},
   "source": [
    "# Load custom text in octis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e780cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\OneDrive\\Documenti\\Fede\\Unimib\\TESI\\OCTIS\\OCTIS_editbyFR\\OCTIS_py_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898db7e2",
   "metadata": {},
   "source": [
    "## get file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a6b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current wd: c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR\n",
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets\n",
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets/sample_texts/unprepr_docs.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#root_dir = os.path.dirname(os.path.abspath(__file__)) #not working because __file__ isn't defined\n",
    "#print(root_dir)\n",
    "root_dir =  os.getcwd()\n",
    "root_dir = root_dir.replace('\\\\', '/')\n",
    "print('current wd: '+ root_dir)\n",
    "data_path = root_dir + '/preprocessed_datasets'\n",
    "print(data_path)\n",
    "raw_txt_path = data_path + '/sample_texts/unprepr_docs.txt'\n",
    "print(raw_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968630b8",
   "metadata": {},
   "source": [
    "## preprocessing of raw txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7aa90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 3641.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "11\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "bob dylan born robert allen zimmerman may is an american singer songwriter author and visual artist often regarded as one of the greatest songwriters of all time dylan has been a major figure in popular culture for more than years\n",
      "toni piispanen born july is a paralympic athlete for finland he started as an able bodied karate competitor and became disabled due to an accident that injured his spinal cord at a karate show in this accident occurred in lahti in front of hundreds of spectators\n",
      "created vocab\n",
      "263\n",
      "words filtering done\n",
      "\n",
      "\n",
      "None\n",
      "['accident' 'accords' 'adamson' 'addison']\n",
      "263\n",
      "['bob', 'dylan', 'robert', 'allen', 'zimmerman', 'american', 'singer', 'songwriter', 'author', 'visual', 'artist', 'often', 'regarded', 'one', 'greatest', 'songwriters', 'all', 'time', 'dylan', 'has', 'been', 'major', 'popular', 'culture', 'more', 'than', 'years']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing of sample texts\n",
    "root_dir =  os.getcwd()\n",
    "root_dir = root_dir.replace('\\\\', '/')\n",
    "data_path = root_dir + '/preprocessed_datasets'\n",
    "raw_txt_path = data_path + '/sample_texts/unprepr_docs.txt'\n",
    "\n",
    "p = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=False,  stopword_list='english', split=False,\n",
    "                    min_chars=2, min_words_docs=1,\n",
    "                    max_df=1, min_df=0, language='english',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "dataset = p.preprocess_dataset(\n",
    "    documents_path=raw_txt_path,   #each row of the txt file is seen as a single document\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(dataset.dataset_path)\n",
    "print(dataset.get_vocabulary()[1:5])\n",
    "print(dataset.get_vocabulary().size)\n",
    "print(dataset.get_corpus()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d98df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2225/2225 [00:00<00:00, 43629.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro ended\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "2949\n",
      "words filtering done\n",
      "\n",
      "\n",
      "None\n",
      "['abide' 'ability' 'abolish' 'abroad']\n",
      "2949\n",
      "['broadband', 'ahead', 'join', 'internet', 'fast', 'accord', 'official', 'figure', 'number', 'business', 'connect', 'jump', 'report', 'broadband', 'connection', 'end', 'compare', 'nation', 'rank', 'world', 'telecom', 'body', 'election', 'campaign', 'ensure', 'affordable', 'high', 'speed', 'net', 'access', 'american', 'accord', 'report', 'broadband', 'increasingly', 'popular', 'research', 'shopping', 'download', 'music', 'watch', 'video', 'total', 'number', 'business', 'broadband', 'rise', 'end', 'compare', 'hook', 'broadband', 'subscriber', 'line', 'technology', 'ordinary', 'phone', 'line', 'support', 'high', 'data', 'speed', 'cable', 'lead', 'account', 'line', 'broadband', 'phone', 'line', 'connection', 'accord', 'figure']\n"
     ]
    }
   ],
   "source": [
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## preprocessing of BBC news with labels\n",
    "root_dir =  os.getcwd()\n",
    "root_dir = root_dir.replace('\\\\', '/')\n",
    "data_path = root_dir + '/preprocessed_datasets'\n",
    "raw_txt_path = data_path + '/BBC_news/corpus.txt'\n",
    "raw_labels_path = data_path + '/BBC_news/labels.txt'\n",
    "\n",
    "p = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=False,  stopword_list='english', split=False,\n",
    "                    min_chars=2, min_words_docs=1,\n",
    "                    max_df=1.0, min_df=0.0, language='english',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "dataset = p.preprocess_dataset(\n",
    "    documents_path=raw_txt_path,   #each row of the txt file is seen as a single document\n",
    "    #labels_path = raw_labels_path\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(dataset.dataset_path)\n",
    "print(dataset.get_vocabulary()[1:5])\n",
    "print(dataset.get_vocabulary().size)\n",
    "print(dataset.get_corpus()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca3acfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "p = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=False,  stopword_list='english', split=False,\n",
    "                    min_chars=2, min_words_docs=1,\n",
    "                    max_df=1.0, min_df=0.0, language='english',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "docs = [line.strip() for line in open(raw_txt_path, 'r').readlines()]\n",
    "vectorizer = TfidfVectorizer(max_df=p.max_df, min_df=p.min_df, lowercase=p.lowercase,\n",
    "                                         token_pattern=r\"(?u)\\b[\\w|\\-]{\" + str(p.min_chars) + r\",}\\b\",\n",
    "                                         stop_words=p.stopwords)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_df=1, min_df=0, lowercase=True,\n",
    "#                                           token_pattern=r\"(?u)\\b[\\w|\\-]{\" + str(2) + r\",}\\b\",\n",
    "#                                           stop_words=[])\n",
    "\n",
    "vectorizer.fit_transform(docs)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b042e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2225x2949 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 182484 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "docs = [line.strip() for line in open(raw_txt_path, 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95,              # Exclude overly common terms\n",
    "    min_df=2,                 # Keep terms that appear in at least 2 docs\n",
    "    lowercase=True,\n",
    "    token_pattern=r\"(?u)\\b[\\w\\-]{2,}\\b\",  # Match words of at least 2 characters\n",
    "    stop_words=None           # or use 'english' to remove common English stop words\n",
    ")\n",
    "\n",
    "vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7f1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon' 'abide' 'ability' ... 'youngster' 'youth' 'zone']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05f864",
   "metadata": {},
   "source": [
    "# load dataset from octis library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f7ef9",
   "metadata": {},
   "source": [
    "## load_custom_dataset_from_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cf4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets/BBC_News\n",
      "\n",
      "\n",
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets/BBC_News\n",
      "['boost', 'profit', 'medium', 'jump']\n",
      "2949\n",
      "['broadband', 'ahead', 'join', 'internet', 'fast', 'accord', 'official', 'figure', 'number', 'business', 'connect', 'jump', 'report', 'broadband', 'connection', 'end', 'compare', 'nation', 'rank', 'world', 'telecom', 'body', 'election', 'campaign', 'ensure', 'affordable', 'high', 'speed', 'net', 'access', 'american', 'accord', 'report', 'broadband', 'increasingly', 'popular', 'research', 'shopping', 'download', 'music', 'watch', 'video', 'total', 'number', 'business', 'broadband', 'rise', 'end', 'compare', 'hook', 'broadband', 'subscriber', 'line', 'technology', 'ordinary', 'phone', 'line', 'support', 'high', 'data', 'speed', 'cable', 'lead', 'account', 'line', 'broadband', 'phone', 'line', 'connection', 'accord', 'figure']\n"
     ]
    }
   ],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "\n",
    "root_dir =  os.getcwd().replace('\\\\', '/')\n",
    "data_path = root_dir + '/preprocessed_datasets'\n",
    "dataset_path = data_path + '/BBC_News'\n",
    "print(dataset_path)\n",
    "\n",
    "mydata = Dataset()\n",
    "mydata.load_custom_dataset_from_folder(dataset_path)\n",
    "\n",
    "print('\\n')\n",
    "print(mydata.dataset_path)\n",
    "print(mydata.get_vocabulary()[1:5])\n",
    "print(np.array(mydata.get_vocabulary()).size)\n",
    "print(mydata.get_corpus()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0d546",
   "metadata": {},
   "source": [
    "## fetch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ecec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets/BBC_News\n",
      "['boost', 'profit', 'medium', 'jump']\n",
      "2949\n",
      "['broadband', 'ahead', 'join', 'internet', 'fast', 'accord', 'official', 'figure', 'number', 'business', 'connect', 'jump', 'report', 'broadband', 'connection', 'end', 'compare', 'nation', 'rank', 'world', 'telecom', 'body', 'election', 'campaign', 'ensure', 'affordable', 'high', 'speed', 'net', 'access', 'american', 'accord', 'report', 'broadband', 'increasingly', 'popular', 'research', 'shopping', 'download', 'music', 'watch', 'video', 'total', 'number', 'business', 'broadband', 'rise', 'end', 'compare', 'hook', 'broadband', 'subscriber', 'line', 'technology', 'ordinary', 'phone', 'line', 'support', 'high', 'data', 'speed', 'cable', 'lead', 'account', 'line', 'broadband', 'phone', 'line', 'connection', 'accord', 'figure']\n"
     ]
    }
   ],
   "source": [
    "mydata2 = Dataset()\n",
    "mydata2.fetch_dataset('BBC_News')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(mydata.dataset_path)\n",
    "print(mydata.get_vocabulary()[1:5])\n",
    "print(np.array(mydata.get_vocabulary()).size)\n",
    "print(mydata.get_corpus()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbe270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'octis.dataset.dataset.Dataset'>\n",
      "<class 'octis.dataset.dataset.Dataset'>\n",
      "<class 'octis.dataset.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mydata))\n",
    "print(type(dataset))\n",
    "print(type(mydata2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ed629",
   "metadata": {},
   "source": [
    "## analysis of the dataset loader functions\n",
    "\n",
    "the functions used are:\n",
    "\n",
    "- dataset.fetch_dataset , that (when data_home=None, that is the most frequent case) simply calls dataset.downloader.download_dataset\n",
    "\n",
    "- dataset.load_custom_dataset_from_folder, that uses pandas\n",
    "\n",
    "- preprocessing.load_custom_dataset_from_folder, that works with a txt file. This function extrapolate 4 lists (corpus, vocabulary, indexes, optionally labels) and the metadata dictionary. The labels require a second file path. Then passes this things to the Dataset class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5f2c6",
   "metadata": {},
   "source": [
    "## preprocess_csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ba2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\OneDrive\\Documenti\\Fede\\Unimib\\TESI\\OCTIS\\OCTIS_editbyFR\\OCTIS_py_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5fb6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting it-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "Installing collected packages: it-core-news-sm\n",
      "Successfully installed it-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('it_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\feder\\OneDrive\\Documenti\\Fede\\Unimib\\TESI\\OCTIS\\OCTIS_editbyFR\\OCTIS_py_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29baf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=True,  stopword_list='italian', split=False,\n",
    "                    min_chars=3, min_words_docs=1,\n",
    "                    max_df=1.0, min_df=0.0, language='italian',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "\n",
    "root_dir =  os.getcwd().replace('\\\\', '/')\n",
    "data_path = root_dir + '/preprocessed_datasets'\n",
    "dataset_path = data_path + '/codici040I.csv'\n",
    "print(dataset_path)\n",
    "\n",
    "mydata = p.preprocess_csv_dataset(dataset_path, sep=';', docs_colname='testoArt', labels_colname=None)#'nomeAtto')\n",
    "print(mydata.get_metadata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27d146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "c:/Users/feder/OneDrive/Documenti/Fede/Unimib/TESI/OCTIS/OCTIS_editbyFR/preprocessed_datasets/BBC_News\n",
      "['boost', 'profit', 'medium', 'jump', 'month', 'early', 'firm', 'big', 'investor', 'benefit', 'high', 'speed', 'internet', 'connection', 'advert', 'fourth', 'quarter', 'rise', 'gain', 'offset', 'dip', 'user', 'search', 'engine', 'business', 'mix', 'fortune', 'lose', 'subscriber', 'low', 'company', 'item', 'back', 'strong', 'advertising', 'revenue', 'hope', 'increase', 'offer', 'online', 'service', 'free', 'customer', 'sign', 'exist', 'broadband', 'result', 'follow', 'probe']\n",
      "2949\n",
      "[['broadband', 'ahead', 'join', 'internet', 'fast', 'accord', 'official', 'figure', 'number', 'business', 'connect', 'jump', 'report', 'broadband', 'connection', 'end', 'compare', 'nation', 'rank', 'world', 'telecom', 'body', 'election', 'campaign', 'ensure', 'affordable', 'high', 'speed', 'net', 'access', 'american', 'accord', 'report', 'broadband', 'increasingly', 'popular', 'research', 'shopping', 'download', 'music', 'watch', 'video', 'total', 'number', 'business', 'broadband', 'rise', 'end', 'compare', 'hook', 'broadband', 'subscriber', 'line', 'technology', 'ordinary', 'phone', 'line', 'support', 'high', 'data', 'speed', 'cable', 'lead', 'account', 'line', 'broadband', 'phone', 'line', 'connection', 'accord', 'figure'], ['plan', 'share', 'sale', 'owner', 'technology', 'dominate', 'index', 'plan', 'sell', 'share', 'public', 'list', 'market', 'operate', 'accord', 'document', 'file', 'stock', 'market', 'plan', 'raise', 'sale', 'observer', 'step', 'close', 'full', 'public', 'icon', 'technology', 'boom', 'recently', 'pour', 'cold', 'water', 'suggestion', 'company', 'sell', 'share', 'private', 'technically', 'public', 'stock', 'start', 'trade', 'list', 'equity', 'trade', 'money', 'sale', 'investor', 'buy', 'share', 'private', 'filing', 'document', 'share', 'technology', 'firm', 'company', 'high', 'growth', 'potential', 'symbol', 'internet', 'telecom', 'boom', 'bubble', 'burst', 'recovery', 'fortune', 'tech', 'giant', 'dot', 'revive', 'fortune'], ['mobile', 'rack', 'mobile', 'phone', 'celebrate', 'anniversary', 'weekend', 'mobile', 'phone', 'call', 'vodafone', 'network', 'veteran', 'day', 'mobile', 'phone', 'integral', 'part', 'modern', 'life', 'briton', 'handset', 'mobile', 'popular', 'handset', 'phone', 'rarely', 'call', 'portable', 'phone', 'commercial', 'mobile', 'service', 'launch', 'rest', 'world', 'set', 'network', 'call', 'walk', 'call', 'office', 'house', 'day', 'vodafone', 'firm', 'mobile', 'network', 'launch', 'service', 'spokesman', 'phone', 'launch', 'size', 'cost', 'battery', 'life', 'minute', 'hugely', 'popular', 'mid', 'status', 'symbol', 'young', 'business', 'fact', 'phone', 'radio', 'signal', 'communicate', 'easy', 'rack', 'customer', 'month', 'easy', 'forget', 'put', 'bid', 'document', 'forecast', 'total', 'market', 'forecast', 'vodafone', 'customer', 'vodafone', 'mobile', 'phone', 'operator', 'launch', 'launch', 'newcomer', 'operate', 'mobile', 'network', 'operator', 'technology', 'spectrum', 'phone', 'retire', 'call', 'global', 'system', 'mobile', 'widely', 'phone', 'technology', 'planet', 'call', 'digital', 'technology', 'introduce', 'thing', 'text', 'mobile', 'popular']]\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(mydata.dataset_path)\n",
    "print(mydata.get_vocabulary()[1:50])\n",
    "print(np.array(mydata.get_vocabulary()).size)\n",
    "print(mydata.get_corpus()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6dd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "print(len(mydata.get_corpus()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a016bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0    1\n",
      "0       business  510\n",
      "1  entertainment  386\n",
      "2       politics  417\n",
      "3          sport  511\n",
      "4           tech  401\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ar = np.array(mydata.get_labels())\n",
    "print(pd.DataFrame(np.unique(ar, return_counts=True, equal_nan=False)).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c743f",
   "metadata": {},
   "source": [
    "# preprocessing txt vs csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "\n",
    "root_dir =  os.getcwd().replace('\\\\', '/')\n",
    "data_path = root_dir + '/preprocessed_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b115cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2225/2225 [00:00<00:00, 37085.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro ended\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "2949\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "p_eng = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=False,  stopword_list='english', split=False,\n",
    "                    min_chars=2, min_words_docs=1,\n",
    "                    max_df=1, min_df=0, language='english',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "raw_txt_path = data_path + '/BBC_news/corpus.txt'\n",
    "raw_labels_path = data_path + '/BBC_news/labels.txt'\n",
    "\n",
    "dataset = p_eng.preprocess_dataset(\n",
    "    documents_path=raw_txt_path,   #each row of the txt file is seen as a single document\n",
    "    labels_path = raw_labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2129a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydocs = [line.strip() for line in open(raw_txt_path, 'r').readlines()]\n",
    "mylabels = [line.strip() for line in open(raw_txt_path, 'r').readlines()]\n",
    "mydocs = pd.DataFrame({'texts' : mydocs, 'labels' : mylabels})\n",
    "csv_path = data_path + '/BBC_news/textdata.csv'\n",
    "mydocs.to_csv(csv_path, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a0f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2225/2225 [00:00<00:00, 47346.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro ended\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "2949\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "dataset = p_eng.preprocess_csv_dataset(csv_path, sep=';', docs_colname='texts')#, labels_colname='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54acc7",
   "metadata": {},
   "source": [
    "# italian csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18beec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18718/18718 [19:03<00:00, 16.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple prepro ended\n",
      "created vocab\n",
      "21480\n",
      "there are labels with texts\n",
      "Filtered out docs: 0\n",
      "num of docs: 18718\n",
      "num of labels to remove: 0\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_it = Preprocessing(vocabulary=None, max_features=None, remove_punctuation=True,\n",
    "                    lemmatize=True,  stopword_list='italian', split=False,\n",
    "                    min_chars=3, min_words_docs=1,\n",
    "                    max_df=1, min_df=0, language='italian',\n",
    "                    remove_stopwords_spacy = True,\n",
    "                    verbose=True)\n",
    "\n",
    "dataset_path = data_path + '/codici040I.csv'\n",
    "\n",
    "mydata = p_it.preprocess_csv_dataset(dataset_path, sep=';', docs_colname='testoArt', labels_colname='nomeAtto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba50c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "None\n",
      "['aaaa' 'aap' 'aarhus' 'abato' 'abbagliamente' 'abbagliamento'\n",
      " 'abbagliante' 'abbagliare' 'abbandona' 'abbandonare' 'abbandonato'\n",
      " 'abbandono' 'abbassamento' 'abbassare' 'abbattere' 'abbattimento'\n",
      " 'abbazia' 'abbellimento' 'abbiente' 'abbigliamento' 'abbinabile'\n",
      " 'abbinabilita' 'abbinabilito' 'abbinamento' 'abbinare' 'abbinato'\n",
      " 'abbisogna' 'abbisognare' 'abbonamento' 'abbonare' 'abbonato'\n",
      " 'abbondante' 'abbordo' 'abbreviabile' 'abbreviandolo' 'abbreviare'\n",
      " 'abbreviato' 'abbreviazione' 'abbruciamento' 'abbuone' 'abe' 'abi'\n",
      " 'abietto' 'abile' 'abili' 'abilire' 'abilita' 'abilitante' 'abilitare']\n",
      "21480\n",
      "[['capo', 'provvisorio', 'vedere', 'deliberazione', 'assemblea', 'costituente', 'seduta', 'dicembre', 'approvare', 'costituzione', 'italiano', 'vedere', 'xviii', 'disposizione', 'finale', 'costituzione', 'promulgare', 'costituzione', 'italiano', 'testo', 'articolo', 'repubblica', 'democratico', 'fondato', 'sovranita', 'appartenere', 'popolo', 'esercitare', 'forma', 'limite', 'costituzione'], ['articolo', 'repubblica', 'riconoscere', 'garantire', 'diritto', 'inviolabile', 'singolo', 'formazione', 'sociale', 'ove', 'svolgere', 'personalita', 'richiedere', 'adempimento', 'dovere', 'inderogabile', 'solidarieta', 'politico', 'economico', 'sociale'], ['articolo', 'cittadino', 'pari', 'dignita', 'sociale', 'eguale', 'legge', 'distinzione', 'sesso', 'razza', 'lingua', 'religione', 'opinione', 'politico', 'condizione', 'personale', 'sociale', 'compito', 'repubblica', 'rimuovere', 'ostacolo', 'ordine', 'economico', 'sociale', 'limitare', 'liberto', 'eguaglianza', 'cittadino', 'impedire', 'sviluppo', 'persona', 'umano', 'effettivo', 'partecipazione', 'lavoratore', 'organizzazione', 'politico', 'economico', 'sociale']]\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(mydata.dataset_path)\n",
    "print(mydata.get_vocabulary()[1:50])\n",
    "print(np.array(mydata.get_vocabulary()).size)\n",
    "print(mydata.get_corpus()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8138cb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Costituzione ',\n",
       " 'Codice penale',\n",
       " 'Codice di procedura civile',\n",
       " 'Codici penali militari di pace e di guerra',\n",
       " 'Codice civile',\n",
       " 'Codice civile',\n",
       " 'Codice civile',\n",
       " 'Codice della navigazione',\n",
       " 'Codice della navigazione',\n",
       " 'Codice postale e delle telecomunicazioni']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.get_labels()[0:10000:1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCTIS_py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
